{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "np.set_printoptions(linewidth=130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedback-prize-english-language-learning.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "compname = 'feedback-prize-english-language-learning'\n",
    "\n",
    "if iskaggle: path = Path('../input/'+compname)\n",
    "else:\n",
    "    import zipfile,kaggle\n",
    "    path = Path(compname)\n",
    "    kaggle.api.competition_download_cli(str(path))\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
    "\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "tst_df = pd.read_csv(path/'test.csv')\n",
    "modes = df.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\tsample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and st...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  \\\n",
       "0  0016926B079C   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
       "0  I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and st...   \n",
       "\n",
       "   cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0       3.5     3.5         3.0          3.0      4.0          3.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       20.0\n",
       "1       14.5\n",
       "2       18.0\n",
       "3       27.0\n",
       "4       16.5\n",
       "        ... \n",
       "3906    17.0\n",
       "3907    22.5\n",
       "3908    18.0\n",
       "3909    26.0\n",
       "3910    19.0\n",
       "Length: 3911, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=[np.number]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def proc_data(df):\n",
    "    if not 'score' in df.columns:\n",
    "        df['score'] = df.select_dtypes(include=[np.number]).sum(axis=1)\n",
    "\n",
    "proc_data(df)\n",
    "proc_data(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and st...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  \\\n",
       "0  0016926B079C   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
       "0  I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and st...   \n",
       "\n",
       "   cohesion  syntax  vocabulary  phraseology  grammar  conventions  score  \n",
       "0       3.5     3.5         3.0          3.0      4.0          3.0   20.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_scored = df.score.idxmax()\n",
    "max_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall essay:\n",
      "I agree with Michelangelo's statement as I have found through experience that it benefits me more to set high expectations and not reach my goal, rather than settling on a low goal and achieving it. When setting high goals, I find that I learn more and progress my abilties further than I do with a lower goal. This is because setting high goals requires confidence, challenges, and pride.\n",
      "\n",
      "Firstly, hard work is required to achieve high goals, and requires confidence. Confidence involves having trust and believing that you are capable of accomplishing something. I have found that when I set high goals, I feel more confident in my abilities. With lower goals however, my confidence is lower as I settle for the easier path and do not trust myself to do better. With a higher aim, my confidence motivates me to not give up. I tend to try harder, and always believe in myself. For example, at school, I had to choose whether I wanted to try out for the varsity tennis team or remain in the club team. The varsity team was a higher reach, and required confidence in my abilities for me to try out. The club team was a lower reach, as I knew that I could simply continue with it. I decided to try out for the varsity team, and was confident in my abilities. I practiced hard and did not give up. Despite not making it onto the team, I found that I actually greatly improved my abilities through the confidence I had gained, and tried harder than I had ever before. I managed to progress my skills, and was able to play more confidently on the club team and excel. Therefore, setting high aims requires confidence, which is a very beneficial characteristic to have in life.\n",
      "\n",
      "Secondly, setting a high goal indicates a challenge. It will be more challenging to attempt to aim high rather than aiming low, yet this will also prove more benefits. With a challenge, I tend to be more motivated as I want to prove my capabilites. I try harder, and in return get further. Even if I fall short of my high aim, I tend to get further than I would have if I had settled with a lower aim. With lower goals, there is no challenge, and so once the aim is achieved any effort stops. Learning is limited to that low expectation, and will not be able to go beyond. For example, in my high school career, I have always struggled with picking between two types of courses: honors or academic. Honors is the more challenging course, which requires more work and effort and would pose as more of a challenge. Academic however, requires the bare minimum and is easy to succeed in. In the honors course, I would be setting my aim high yet might not get the grade I want; yet, in the academic course, my aim would be low and I would most likely get the grade I want. After hard consideration, I decided to opt for the honors course. This course may be a challenge, yet would allow me to learn more. I enjoyed the challenge, and found that it motivated me to try harder to try and accomplish my goal. Even if I fell short of my ideal grade, I was proud to have tried my best and felt that I learnt so much more. The course benefited me more than the academic course would have, despite not receiving the grade I hoped for. Therefore, challenging oneself with a high aim allows for more flourishing and encourages more learning. Overall, setting a high aim will pose more benefits.\n",
      "\n",
      "Thirdly, pride accompanies setting high goals. When setting low aims, I feel that it is easy to achieve the goal. However, with high aims, it is more challenging to achieve the goal, and so I feel proud of myself for attempting it. Pride is a very important characteristic, as it increases self esteem. With a higher self-esteem, I tend to try harder and feel more powerful with my abilities. I am more likely to learn and improve upon my abilities, which overall allows me to succeed. For example, in high school I had the opportunity to write a poem and submit it into a writing competition. This was a high aim, as the goal was to win. I felt very proud of myself for taking the time to write and challenge myself with this competition, and ended up writing my favorite piece yet. I submitted my writing, and did not win. However, I felt very proud of myself for having tried so hard and was able to learn and flourish in my writing abilities. Now, I am more likely to sign up for competitions, even if I do not win, simply because I enjoy the challenge and feel that I am able to learn. I feel proud of myself for taking on these challenges. Therefore, setting high goals emmits pride, which can prove very beneficial in life.\n",
      "\n",
      "In conclusion, I agree with Michelangelo's statement. Setting high aims and falling short can bring so many more positive effects than setting low aims and accomplishing them. This is because setting high aims requires confidence, challenges, and pride. These characteristics are very important in succeeding, and can encourage learning and progression in abilities. Through setting low goals, learning becomes stagnant. In order to flourish and continue learning, setting high goals is crucial, even when not achieving the goal. \n"
     ]
    }
   ],
   "source": [
    "print('Best overall essay:')\n",
    "print(df.loc[max_scored].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_id        0\n",
       "full_text      0\n",
       "cohesion       0\n",
       "syntax         0\n",
       "vocabulary     0\n",
       "phraseology    0\n",
       "grammar        0\n",
       "conventions    0\n",
       "score          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check for missing data\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_id',\n",
       " 'full_text',\n",
       " 'cohesion',\n",
       " 'syntax',\n",
       " 'vocabulary',\n",
       " 'phraseology',\n",
       " 'grammar',\n",
       " 'conventions',\n",
       " 'score']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
       "       'phraseology', 'grammar', 'conventions', 'score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see general training set statistics\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a basic text learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = TextDataLoaders.from_df(df, path, text_col='full_text', label_col='cohesion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='15' class='' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      31.25% [15/48 00:05&lt;00:11 2.3857]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/callback/schedule.py:293\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    291\u001b[0m n_epoch \u001b[38;5;241m=\u001b[39m num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    292\u001b[0m cb\u001b[38;5;241m=\u001b[39mLRFinder(start_lr\u001b[38;5;241m=\u001b[39mstart_lr, end_lr\u001b[38;5;241m=\u001b[39mend_lr, num_it\u001b[38;5;241m=\u001b[39mnum_it, stop_div\u001b[38;5;241m=\u001b[39mstop_div)\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_logging(): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggest_funcs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     lrs, losses \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlrs[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]), tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorder\u001b[38;5;241m.\u001b[39mlosses[num_it\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:256\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:245\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:231\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:227\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:193\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/text/models/core.py:98\u001b[0m, in \u001b[0;36mSentenceEncoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, sl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbptt):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m#Note: this expects that sequence really begins on a round multiple of bptt\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     real_bs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28minput\u001b[39m[:,i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_idx)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 98\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mreal_bs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbptt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m sl\u001b[38;5;241m-\u001b[39mi \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len:\n\u001b[1;32m    100\u001b[0m         outs\u001b[38;5;241m.\u001b[39mappend(o)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/text/models/awdlstm.py:128\u001b[0m, in \u001b[0;36mAWD_LSTM.forward\u001b[0;34m(self, inp, from_embeds)\u001b[0m\n\u001b[1;32m    126\u001b[0m new_hidden \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, (rnn,hid_dp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dps)):\n\u001b[0;32m--> 128\u001b[0m     output, new_h \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     new_hidden\u001b[38;5;241m.\u001b[39mappend(new_h)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m: output \u001b[38;5;241m=\u001b[39m hid_dp(output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/fastai/text/models/awdlstm.py:62\u001b[0m, in \u001b[0;36mWeightDropout.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# To avoid the warning that comes because the weights aren't flattened.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    773\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(5, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos i am agree with the xxmaj waldo xxmaj emerson 's prompt . xxmaj he wrote that \" to be yourself in a world that is constantly trying to make you something else is the greatest accomplishment . \" \\n\\n \" never give up . \" xxmaj this word xxunk our xxunk about our thought . xxmaj it makes us xxunk . xxmaj life is not a bed of rose , life is struggle . xxmaj every single person has their life struggle . xxmaj nobody is a perfect at they look . a perfect man is he who win the struggle . a successful man , he not get success in a second . xxmaj he had lot of struggle in his life , but he do n't stop for his goal . xxmaj after long time keep trying made him successful . xxmaj he adjust the struggle and</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxmaj in the principals office there is quote stating that \" your life can be beneficial if your doing something very productive , because it can lead you to great success in life \" xxmaj in some way we ask ourselves if we are do something with our lives and be thinking ahead on what we want to do with our life and what can take us to success . xxmaj is that true ? . xxmaj its more than just having something to do . xxmaj life is very short , xxmaj as long as you are doing something with success . xxmaj living is an option as well as just giving up and not trying very enough . xxmaj accomplishing something in life to any dream you want to have . xxmaj if you do nt try as hard in life , you will never succeed and</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj if we think about the words that the xxmaj british xxmaj prime xxmaj minister xxmaj wiston xxmaj churchill xxunk \" succes consists of going from failure to failure without loss of enthusiasm . \" xxmaj there is a lot of truth is this words well that is what i believe . xxmaj so how important is the role that failure plays in the process to reach success and do n't loss enthusiasm in the proccess ? xxmaj in my opinion it is very important because it make us gain experience , improve our skills , and it make you feel comfortable and happy at the end . \\n\\n xxmaj xxunk think about how you feel when your staring in the proccess to reach a new goal that you propose to youself it could be hard at the begin , because is your first time in that enviroment and</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos a lot of people accomplish more if they are always doing something and others ask if inactivity also serve as a purpose . xxmaj there is a lot of people doing a lot of activities everyday and some others doing nothing than just watch xxup tv . xxmaj each human person in the world have a purpose , goal to get in a future and is something that we really want to have in our life . xxmaj xxunk purposes do n't come by itself as a miracle . xxmaj every person has a different purpose , some purposes are complicated to reach , and there 's also some less complicated but does n't make any difference because every person decides and picks what are their purposes and whether if they give up or they do anything to reach them . xxmaj thomas xxmaj jefferson wrote \" determine never</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos i feel that working with a partner is more beneficial to students . xxmaj working with partners gets students extra help when in need . xxmaj it can make new friends while working on big projects . xxmaj also it makes the work get done easier and quicker when working in big groups . i also personally think that any project with a presentation should be a group project . xxmaj if that presentation has more than just the presentation it should be a three person group . \\n\\n xxmaj working with a partner is beneficial to students , because it gives extra support or help on a project or classwork . xxmaj if a project is too big and impossible for one person to complete they could split up the work . xxmaj for example , when i had a final project in my english class ; i</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos xxmaj have you ever accomplished something in your life ? xxmaj because people nowadays are very lazy and hard headed because they are easily distracted by social media , people around them , and also the society that 's why they can not focus on their goals in life . xxmaj although some might argue it is not better to work on something to accomplish , actually it is better to work on something to accomplish because you will gain more knowledge and people will be proud to what you 've accomplished . \\n\\n xxmaj one reason why it is better to work on something to accomplish is because you will gain more knowledge . xxmaj for instance , based on my personal experience when i was in middle school , i do nt do my projects , homework , seat works because xxmaj i 'm too lazy and</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos i agree with success consists of going from failure to failure without loss of enthusiasm because everyone need to be stronger , successful , and become independent youself . \\n\\n xxmaj success are things that everybody need to be stronger the most they can with every single thing in your life because everyone has bad moments in lifes and there are many peoples that they want to see them fail in everything . xxmaj for example , if someone is given in they can find someone who is bad person and the only thing that they do is to given words that did not help in anything , but that 's why they have to failure , but do not have to loss enthusiasm because if you loss enthusiasm you are failed in everything because in lifes you can find peoples that want to help you a lot ,</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos xxmaj there 's 90 % of people in the world that wants to be someone in life , but some people never had the chance or some people just gave up on school , and now they regret it . xxmaj in the past few years , there has been many teenagers that go to college and try to do a career that they think they are able to work with , but after few days of studying for that career , they see that that 's not for them , and they just drop out . xxmaj our schools and our parents have been trying to help us decide what we really want to do in our future before we enter college , that way we do n't do the same mistake some people did . xxmaj now schools have a program where you get to choose what</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos xxmaj when you trying to make something different every day , is the greatest accomplishment . \\n\\n xxmaj i 'm agree about xxmaj emerson 's xxmaj statement ! \\n\\n xxmaj well , when you be yourself you every moment want to be something else , something new to know how capacity you have to be yourself . xxmaj when you thinking in yourself your days be more easy , fun , you enjoy yourself in a world because you are only in the world nobody is like you , you are the only who make the better decisions in your life and is something constantly trying to make you something else because is the most and greatest accomplishment that you have is like a gift that your received and you need to care . \\n\\n xxmaj when you constantly trying to make you something you learn something that you</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.9430e-04, 6.2074e-04, 9.1341e-02,  ..., 2.4960e-02, 8.3245e-04,\n",
       "         2.5042e-04],\n",
       "        [8.4127e-04, 7.8517e-04, 2.9472e-02,  ..., 1.3126e-01, 1.1550e-02,\n",
       "         2.0622e-03],\n",
       "        [1.2204e-03, 3.3743e-03, 5.5332e-03,  ..., 3.9556e-01, 1.0615e-01,\n",
       "         7.2997e-03],\n",
       "        ...,\n",
       "        [1.0341e-04, 1.7530e-04, 2.6497e-03,  ..., 4.7920e-01, 3.2254e-02,\n",
       "         3.7362e-03],\n",
       "        [1.6273e-03, 1.8583e-03, 2.4582e-02,  ..., 3.4170e-01, 4.8943e-02,\n",
       "         7.9467e-03],\n",
       "        [1.8655e-04, 2.3037e-03, 5.0473e-01,  ..., 1.0312e-03, 3.7424e-05,\n",
       "         1.4505e-05]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, actuals, decoded = learn.get_preds(with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's use a transformer now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu memory management\n",
    "import gc, torch\n",
    "!pip install -Uqq pynvml\n",
    "\n",
    "def free_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def report_gpu():\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    free_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq transformers\n",
    "!pip install -Uqq ohmeow-blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d509c115344529b8bbb186d1c16e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5587ac67a6d54814b15204df019ef8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "from transformers.utils import logging as hf_logging\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.text.data.all import *\n",
    "from blurr.text.modeling.all import *\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.5, 2.5, 3. , 4.5, 4. , 2. , 1. , 5. , 1.5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"cohesion\"].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = len(labels)\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:0\n",
      "process       2704 uses     1475.000 MB GPU memory\n"
     ]
    }
   ],
   "source": [
    "report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = n_labels\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name,\n",
    "    model_cls=model_cls, \n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>success consist of going from failure to failure withouth loss of enthusiasm, and i'm agree with this statement, because can do what it wants if try and try, and everything is doing with effort, and than a failure can be for a better oportunity in th</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generic _ name march 18 2019 writting sol grade 8 before, i would always like to try and play the guitar. my brother would always try and teach me, everytime i hear the guitar, it makes me feel calmed. also when i was in elementary school, i used to</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blocks = (\n",
    "    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), \n",
    "    CategoryBlock\n",
    ")\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks, \n",
    "    get_x=ColReader(\"full_text\"), \n",
    "    get_y=ColReader(\"cohesion\"), \n",
    "    splitter=RandomSplitter(valid_pct=0.2)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(df, bs=32)\n",
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam, decouple_wd=True),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy, error_rate],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0002511886414140463, steep=0.00013182566908653826, valley=5.248074739938602e-05)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=(minimum, steep, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.641724</td>\n",
       "      <td>1.559415</td>\n",
       "      <td>0.320972</td>\n",
       "      <td>0.679028</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.508509</td>\n",
       "      <td>1.627656</td>\n",
       "      <td>0.301790</td>\n",
       "      <td>0.698210</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.474431</td>\n",
       "      <td>1.461606</td>\n",
       "      <td>0.349105</td>\n",
       "      <td>0.650895</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.385645</td>\n",
       "      <td>1.439419</td>\n",
       "      <td>0.351662</td>\n",
       "      <td>0.648338</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.147156</td>\n",
       "      <td>1.598275</td>\n",
       "      <td>0.335038</td>\n",
       "      <td>0.664962</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.923578</td>\n",
       "      <td>1.703534</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

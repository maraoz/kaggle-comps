{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3394be9-e879-4615-9f21-21f0b9a5bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to download competitions/aiornot to downloads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration competitions--aiornot-c64672d1851055ac\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/competitions___parquet/competitions--aiornot-c64672d1851055ac/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46e2bd865ae4c149f4e6e6e34ff4eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face dataset bootstrapping\n",
    "OWNER_NAME = 'competitions/'\n",
    "DATASET_NAME = 'aiornot'\n",
    "\n",
    "!pip install -Uqq datasets\n",
    "!pip install -Uqq python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "load_dotenv('/notebooks/.env')\n",
    "access_token = os.environ.get('HF_TOKEN')\n",
    "DOWNLOADS = Path('downloads')\n",
    "path = DOWNLOADS/DATASET_NAME\n",
    "\n",
    "print('about to download', OWNER_NAME+DATASET_NAME, 'to', DOWNLOADS)\n",
    "ds = load_dataset(OWNER_NAME+DATASET_NAME, use_auth_token=access_token)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad90f0f-2bbe-4acd-b218-f706ac0c1d49",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Moving csv format to images in folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f58cee-5b97-4d9d-a36e-d9e9a27e4bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'image', 'label'],\n",
       "        num_rows: 18618\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'image', 'label'],\n",
       "        num_rows: 43442\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Image as ImageFeature\n",
    "ds = ds.cast_column('image', ImageFeature())\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d269269-da2c-4c17-8656-ce80e8609d3c",
   "metadata": {},
   "source": [
    "Let's save the dataset in folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011bd076-c8d7-46ed-99a9-7c345da023a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('downloads/aiornot')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0938a329-d945-4d2b-898c-beb90a335cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45b0d05-88f0-44ed-80aa-b4ea7983d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'train'/'0').mkdir(exist_ok=True)\n",
    "(path/'train'/'1').mkdir(exist_ok=True)\n",
    "(path/'test'/'0').mkdir(exist_ok=True)\n",
    "(path/'test'/'1').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9c928f-b04f-4fca-88b9-ff840ca3b17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# save train images to folder\n",
    "#for i, fname in tqdm(enumerate(ds['train']['id']), total=ds['train'].num_rows):\n",
    "#    img = ds['train'][i]['image']\n",
    "#    label = str(ds['train'][i]['label'])\n",
    "#    fpath = path/'train'/label/fname\n",
    "#    #print(fpath)\n",
    "#    if not fpath.is_file():\n",
    "#        img.save(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4c652e-362a-4066-9439-e20ee69bb0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save test images to folder\n",
    "#for i, fname in tqdm(enumerate(ds['test']['id']), total=ds['test'].num_rows):\n",
    "#    img = ds['test'][i]['image']\n",
    "#    label = str(ds['test'][i]['label'])\n",
    "#    fpath = path/'test'/fname\n",
    "#    #print(fpath)\n",
    "#    if not fpath.is_file():\n",
    "#        img.save(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff5f03-bfaa-4075-8869-411e4ee497d3",
   "metadata": {},
   "source": [
    "### fastai baseline vision learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fef0c8c-58e9-4217-b185-8063d9df35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu memory management\n",
    "import gc, torch\n",
    "!pip install -Uqq pynvml\n",
    "\n",
    "def free_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def report_gpu():\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    free_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c750ec12-7839-4177-af19-22fe19694775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "files = get_image_files(path/'train')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f216871a-a51c-4e39-8717-ed7a3c8300ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:0\n",
      "no processes are running\n"
     ]
    }
   ],
   "source": [
    "report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b7c901-2ee7-4862-9006-343b4b0364fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465 117\n"
     ]
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path/'train', valid_pct=0.2, bs=32)\n",
    "print(len(dls.train), len(dls.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05f4481e-a8c6-41cc-9f65-e24b65c7e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet50, metrics=error_rate, cbs=GradientAccumulation(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f532c32-1505-48b0-88af-ef88f027c494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='83' class='' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      17.85% [83/465 00:45&lt;03:28 0.5178]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(epochs=5, base_lr=1e-3, freeze_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e5f48-691c-4142-b4e2-bd9d79c49f80",
   "metadata": {},
   "source": [
    "## Evaluate on test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aa4d4-a155-4f30-affd-56cc1c95cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = get_image_files(path/'test')\n",
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "70f76d3b-f5f9-4f82-b09b-a68bfb6d799b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = learn.dls.test_dl(test_files)\n",
    "preds, = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5f3e1ff7-a2e6-4d6c-8ade-1052da9548d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase([9.9998e-01, 1.5562e-04, 9.9684e-01,  ..., 2.0520e-07,\n",
       "            9.9998e-01, 9.9999e-01])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408213c7-8c34-4058-a647-69c12bc57374",
   "metadata": {},
   "source": [
    "## Prepare submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "62003db8-e87a-41b6-922e-b9e775122e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43442, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path/'sample_submission.csv')\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d4125fbf-a209-4f89-a863-b1068272234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>9.999846e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1.556160e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>9.968406e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>5.743017e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>9.999951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43437</th>\n",
       "      <td>9995.jpg</td>\n",
       "      <td>9.411466e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43438</th>\n",
       "      <td>9996.jpg</td>\n",
       "      <td>9.996895e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43439</th>\n",
       "      <td>9997.jpg</td>\n",
       "      <td>2.051955e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43440</th>\n",
       "      <td>9998.jpg</td>\n",
       "      <td>9.999838e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43441</th>\n",
       "      <td>9999.jpg</td>\n",
       "      <td>9.999938e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         label\n",
       "0         0.jpg  9.999846e-01\n",
       "1         1.jpg  1.556160e-04\n",
       "2        10.jpg  9.968406e-01\n",
       "3       100.jpg  5.743017e-06\n",
       "4      1000.jpg  9.999951e-01\n",
       "...         ...           ...\n",
       "43437  9995.jpg  9.411466e-01\n",
       "43438  9996.jpg  9.996895e-01\n",
       "43439  9997.jpg  2.051955e-07\n",
       "43440  9998.jpg  9.999838e-01\n",
       "43441  9999.jpg  9.999938e-01\n",
       "\n",
       "[43442 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.label = decoded\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c390b9aa-28d9-4746-b766-44a00d6099b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629704"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36798405-f7f2-400f-a07c-0a6ab2c0245c",
   "metadata": {},
   "source": [
    "## Submit CSV to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "975ee464-0fd2-41c4-92b2-e748cb03b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# write submission csv\n",
    "technique = '-resnet34 finetune 3 epochs undecoded-'\n",
    "sub_filename = Path('subs')/(DATASET_NAME+'-'+technique+'-sub.csv')\n",
    "submission.to_csv(sub_filename, index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be97c5d-fcce-4794-8b8d-f9873daf828f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
